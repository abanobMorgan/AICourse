{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Instagram with Selenium - UPDATED!\n",
    "\n",
    "### AUTOMATING IMAGE EXTRACTION\n",
    "\n",
    "This Notebook is an <b>upgraded</b> version of the original Web Scraping Instagram with Selenium notebook.\n",
    "<br>\n",
    "This code is asjusted to fit a wider variety of users and has solutions for the issues that arrised in the comment section on YouTube/ issues section on Github.\n",
    "<br>\n",
    "Also, this code is extracting the <b>full size images</b> and not the <b>thumbnails</b>, and it's a <b>100% automated</b>!\n",
    "\n",
    "Please let me know if you have any other problems that you haven't found a solution for in the comment section of the Youtube tutorial:\n",
    "<br>\n",
    "https://youtu.be/iJGvYBH9mcY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports here\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import time\n",
    "\n",
    "import os\n",
    "import wget\n",
    "import errno\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = \"\"\n",
    "password1 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ChromeDriver\n",
    "Now we need to download latest stable release of ChromeDriver from:\n",
    "<br>\n",
    "https://chromedriver.chromium.org/\n",
    "<br>\n",
    "## Log In to Your Instagram Account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Alerts\n",
    "\n",
    "you might only get a single alert, or you might get 2 of them\n",
    "<br>\n",
    "please adjust the cell below accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"E:/new programs/chrome/chromedriver.exe\")\n",
    "\n",
    "def logIn(user1, password1):\n",
    "    \n",
    "    print('start log in to the account ')\n",
    "    #specify the path to chromedriver.exe (download and save on your computer)\n",
    "    #open the webpage\n",
    "    driver.get(\"http://www.instagram.com\")\n",
    "\n",
    "   \n",
    "    username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='username']\")))\n",
    "    password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='password']\")))\n",
    "\n",
    "    #enter username and password\n",
    "    username.clear()\n",
    "    password.clear()\n",
    "    \n",
    "    username.send_keys(user1)\n",
    "    password.send_keys(password1)\n",
    "\n",
    "    #target the login button and click it\n",
    "    button = WebDriverWait(driver, 2).until(EC.element_to_be_clickable(\n",
    "        (By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "\n",
    "    #We are logged in!\n",
    "\n",
    "  \n",
    "    time.sleep(5)\n",
    "    \n",
    "    alert = WebDriverWait(driver, 15).until(EC.element_to_be_clickable(\n",
    "        (By.XPATH, '//button[contains(text(), \"Not Now\")]'))).click()\n",
    "    #alert2 = WebDriverWait(driver, 15).until(EC.element_to_be_clickable(\n",
    "    #(By.XPATH, '//button[contains(text(), \"Not Now\")]'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for a certain hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findImage(name):\n",
    "    print('finding the images ')\n",
    "    #target the search input field\n",
    "    searchbox = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH,\\\n",
    "                                    \"//input[@placeholder='Search']\")))\n",
    "    searchbox.clear()\n",
    "\n",
    "    #search for the hashtag cat\n",
    "    keyword = name\n",
    "    searchbox.send_keys(keyword)\n",
    "    \n",
    "    #FIXING THE DOUBLE ENTER\n",
    "    time.sleep(5) # Wait for 5 seconds\n",
    "    \n",
    "    searchbox.send_keys(Keys.ENTER)\n",
    "    time.sleep(1)\n",
    "    searchbox.send_keys(Keys.ENTER)\n",
    "    \"\"\"my_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable(\n",
    "        (By.XPATH, \"//a[contains(@href= '/explore/tags/\" +keyword[1:]+\"/')]\"))).click()\"\"\"\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scroll Down\n",
    "<br>\n",
    "Increase n_scrolls to select more photos (depending on screen resolution)\n",
    "<br>\n",
    "<b>Example:</b>\n",
    "<br>\n",
    "<ul>\n",
    "    <li>2 scrolls cover approx. 35 photos</li>\n",
    "    <li>3 scrolls cover approx. 45 photos</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll (scrolls):\n",
    "    print('satrt scrolling down ')\n",
    "    #scroll down 2 times\n",
    "    #increase the range to sroll more\n",
    "    n_scrolls = scrolls\n",
    "    for j in range(0, n_scrolls):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetlink():\n",
    "    print('opening the link ')\n",
    "    #target all the link elements on the page\n",
    "    anchors = driver.find_elements_by_tag_name('a')\n",
    "    anchors = [a.get_attribute('href') for a in anchors]\n",
    "    #narrow down all links to image links only\n",
    "    anchors = [a for a in anchors if str(a).startswith(\"https://www.instagram.com/p/\")]\n",
    "\n",
    "    print('Found ' + str(len(anchors)) + ' links to images')\n",
    "    anchors[:5]\n",
    "    a = anchors \n",
    "    print(len(a))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractImages(anchors):\n",
    "    print('extracting the images ')\n",
    "    images = []\n",
    "\n",
    "    #follow each image link and extract only image at index=1\n",
    "    for a in anchors:\n",
    "        driver.get(a)\n",
    "        time.sleep(5)\n",
    "        img = driver.find_elements_by_tag_name('img')\n",
    "        img = [i.get_attribute('src') for i in img]\n",
    "        images.extend(img)\n",
    "        a = images\n",
    "    print('all images are: ', len(images))\n",
    "    return a  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save images to computer\n",
    "\n",
    "First we'll create a new folder for our images somewhere on our computer.\n",
    "<br>\n",
    "Then, we'll save all the images there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createfolder(folderName): \n",
    "    print('creating the folder if it is not found ')\n",
    "    path = os.getcwd()\n",
    "    path = os.path.join(path, folderName[1:] + \"s\")\n",
    "\n",
    "    #create the directory\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "        pass\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download images\n",
    "def imagedawnloader(path,images): \n",
    "    print('start the download ')\n",
    "    counter = 0\n",
    "    for image in images:\n",
    "        save_as = os.path.join(path,  str(counter) + '.jpg')\n",
    "        wget.download(image, save_as)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start log in to the account \n",
      "#cheetah\n",
      "finding the images \n",
      "satrt scrolling down \n",
      "opening the link \n",
      "Found 51 links to images\n",
      "51\n",
      "extracting the images \n",
      "all images are:  801\n",
      "creating the folder if it is not found \n",
      "start the download \n",
      "100% [..............................................................................] 13562 / 13562#lion\n",
      "finding the images \n",
      "satrt scrolling down \n",
      "opening the link \n",
      "Found 42 links to images\n",
      "42\n",
      "extracting the images \n",
      "all images are:  612\n",
      "creating the folder if it is not found \n",
      "start the download \n",
      "100% [..............................................................................] 13562 / 13562#griaffe\n",
      "finding the images \n",
      "satrt scrolling down \n",
      "opening the link \n",
      "Found 39 links to images\n",
      "39\n",
      "extracting the images \n",
      "all images are:  519\n",
      "creating the folder if it is not found \n",
      "start the download \n",
      "100% [..............................................................................] 13562 / 13562#Snake\n",
      "finding the images \n",
      "satrt scrolling down \n",
      "opening the link \n",
      "Found 51 links to images\n",
      "51\n",
      "extracting the images \n",
      "all images are:  670\n",
      "creating the folder if it is not found \n",
      "start the download \n",
      "100% [..............................................................................] 13562 / 13562"
     ]
    }
   ],
   "source": [
    "logIn(user1, password1)\n",
    "tagesname= ['#cheetah',  '#lion','#griaffe','#Snake']\n",
    "with open ('data.csv', 'w') as f: \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"tag\",\"link\"])\n",
    "for tag in tagesname: \n",
    "    print(tag)\n",
    "    findImage(tag)\n",
    "    scroll (20)\n",
    "    anchors = targetlink()\n",
    "    images= extractImages(anchors)\n",
    "    path =createfolder(tag)\n",
    "    imagedawnloader(path,images)\n",
    "    with open ('data.csv', 'a') as f: \n",
    "        writer = csv.writer(f)\n",
    "        for img in range(len(images))  : \n",
    "            \n",
    "            writer.writerow([tag[1:],images[img]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ",'#Crocodile', '#Bear.wild', '#Snake.wild', '#Whale.wild', '#Tiger.wild', '#Lions.wild', '#Eagle.wild','#vulture.wild','#kangaroo.wild', '#monkey.wild' ,' #zebra.wild', '#hippo.wild', '#bull.wild', '#elephant.wild', '#gorilla.wild','#griaffe.wild', '#Ostrich.wild', '#antelope.wild'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " with open ('data.csv', 'a') as f: \n",
    "        writer = csv.writer(f)\n",
    "        for img in range(len(images))  : \n",
    "            \n",
    "            writer.writerow([tag[1:],images[img]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
